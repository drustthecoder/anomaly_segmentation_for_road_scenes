{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6bcqDGPelrF",
        "outputId": "8a143da1-b78c-408b-a2b9-97694d54e67b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMGowi4LfhAV",
        "outputId": "d344b042-67bc-4af9-9e21-19fb8180b59e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 3 minutes\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "!mkdir cityscapes\n",
        "!unzip -qo /content/drive/MyDrive/datasets/leftImg8bit_trainvaltest.zip -d /content/cityscapes\n",
        "!unzip -qo /content/drive/MyDrive/datasets/gtFine_trainvaltest.zip -d /content/cityscapes\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "execution_time = int(execution_time/60)\n",
        "print(\"Execution time:\", execution_time, \"minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3ilxErqiGNF",
        "outputId": "b7e52073-ab35-4c06-ff89-ff3b4ce431d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m768.6 kB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m1.3/1.4 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.6/473.6 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q visdom ood_metrics cityscapesscripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9524JHa5P3AI",
        "outputId": "ceb44f57-1153-4e58-fc78-e7d43ee23001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cityscapesScripts'...\n",
            "remote: Enumerating objects: 648, done.\u001b[K\n",
            "remote: Counting objects: 100% (221/221), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 648 (delta 184), reused 165 (delta 155), pack-reused 427\u001b[K\n",
            "Receiving objects: 100% (648/648), 796.28 KiB | 5.61 MiB/s, done.\n",
            "Resolving deltas: 100% (370/370), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mcordts/cityscapesScripts.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk-D7IPLiJJF",
        "outputId": "5d75545b-555b-4828-95d7-65ea01271a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 5000 annotation files\n",
            "Progress: 100.0 % Execution time: 2 minutes\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "import os\n",
        "os.environ[\"CITYSCAPES_DATASET\"] = \"/content/cityscapes\"\n",
        "!python cityscapesScripts/cityscapesscripts/preparation/createTrainIdLabelImgs.py\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "execution_time = int(execution_time/60)\n",
        "print(\"Execution time:\", execution_time, \"minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sncgFrG3XQ-I",
        "outputId": "b018c1a9-fc44-4f2c-8b9e-df878367faa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'anomaly-segmentation-for-road-scenes'...\n",
            "remote: Enumerating objects: 793, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 793 (delta 63), reused 86 (delta 38), pack-reused 681\u001b[K\n",
            "Receiving objects: 100% (793/793), 562.14 MiB | 39.88 MiB/s, done.\n",
            "Resolving deltas: 100% (181/181), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/shayanit/anomaly-segmentation-for-road-scenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TA9TU1JM6e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b74f39a-721e-418f-f467-f5b936332e0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/anomaly-segmentation-for-road-scenes/train\n"
          ]
        }
      ],
      "source": [
        "%cd /content/anomaly-segmentation-for-road-scenes/train\n",
        "from main import MyCoTransformExtension\n",
        "from dataset import cityscapes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "barlowtwins_resnet = torch.hub.load('facebookresearch/barlowtwins:main', 'resnet50')\n",
        "for param in barlowtwins_resnet.parameters():\n",
        "    param.requires_grad = True #UNFREEZE\n",
        "barlowtwins_resnet = nn.Sequential(*list(barlowtwins_resnet.children())[:-2])\n",
        "num_classes = 20\n",
        "segmentation_head = nn.Conv2d(2048, num_classes, kernel_size=1)\n",
        "upsample = nn.Upsample(size=(224,224), mode='bilinear', align_corners=False)\n",
        "BarlowTwinsModel = nn.Sequential(barlowtwins_resnet, segmentation_head, upsample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfrbgNDGZpyr",
        "outputId": "efe702b6-f9b4-4dcd-bd92-c84c05aff5e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_barlowtwins_main\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5F6Dqm_gNKh",
        "outputId": "7ad214d3-d7a7-461a-d130-2d217bb16cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cityscapes/leftImg8bit/train\n",
            "/content/cityscapes/leftImg8bit/val\n",
            "torch.Size([3, 224, 224])\n",
            "torch.Size([1, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.hub import load as hub_load\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load Cityscapes dataset\n",
        "datadir = '/content/cityscapes'\n",
        "co_transform = MyCoTransformExtension(False, augment=True)\n",
        "co_transform_val = MyCoTransformExtension(False, augment=False)\n",
        "dataset_train = cityscapes(datadir, co_transform, 'train')\n",
        "dataset_val = cityscapes(datadir, co_transform_val, 'val')\n",
        "\n",
        "loader = DataLoader(dataset_train, num_workers=2, batch_size=8, shuffle=True)\n",
        "loader_val = DataLoader(dataset_val, num_workers=2, batch_size=8, shuffle=False)\n",
        "\n",
        "print(dataset_train[0][0].shape)\n",
        "print(dataset_train[0][1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqyT8yIzgW25"
      },
      "source": [
        "#Continue train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1PKyVlF53jH"
      },
      "outputs": [],
      "source": [
        "#Continue train\n",
        "import time\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Instantiate the model\n",
        "model = BarlowTwinsModel\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Choose optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Load the model\n",
        "checkpoint = torch.load('/content/drive/MyDrive/datasets/barlowtwins-frozen.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "loss = checkpoint['loss']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHN0-JeEghRe"
      },
      "source": [
        "#Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FYT3KC7fGtu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a19f3237-a656-40fa-c12c-b64e7ed2b9ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, batch 10/372\n",
            "Epoch 1, batch 20/372\n",
            "Epoch 1, batch 30/372\n",
            "Epoch 1, batch 40/372\n",
            "Epoch 1, batch 50/372\n",
            "Epoch 1, batch 60/372\n",
            "Epoch 1, batch 70/372\n",
            "Epoch 1, batch 80/372\n",
            "Epoch 1, batch 90/372\n",
            "Epoch 1, batch 100/372\n",
            "Epoch 1, batch 110/372\n",
            "Epoch 1, batch 120/372\n",
            "Epoch 1, batch 130/372\n",
            "Epoch 1, batch 140/372\n",
            "Epoch 1, batch 150/372\n",
            "Epoch 1, batch 160/372\n",
            "Epoch 1, batch 170/372\n",
            "Epoch 1, batch 180/372\n",
            "Epoch 1, batch 190/372\n",
            "Epoch 1, batch 200/372\n",
            "Epoch 1, batch 210/372\n",
            "Epoch 1, batch 220/372\n",
            "Epoch 1, batch 230/372\n",
            "Epoch 1, batch 240/372\n",
            "Epoch 1, batch 250/372\n",
            "Epoch 1, batch 260/372\n",
            "Epoch 1, batch 270/372\n",
            "Epoch 1, batch 280/372\n",
            "Epoch 1, batch 290/372\n",
            "Epoch 1, batch 300/372\n",
            "Epoch 1, batch 310/372\n",
            "Epoch 1, batch 320/372\n",
            "Epoch 1, batch 330/372\n",
            "Epoch 1, batch 340/372\n",
            "Epoch 1, batch 350/372\n",
            "Epoch 1, batch 360/372\n",
            "Epoch 1, batch 370/372\n",
            "Epoch 1, batch 372/372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.1280903457313456\n",
            "Validation Loss: 1.1124058176600744\n",
            "Model saved to: /content/drive/MyDrive/datasets/barlowtwins-unfrozen-1.pth\n",
            "Epoch execution time: 34 minutes!\n",
            "Remaining: 9 epochs, about 306 minutes!\n",
            "Best model is: 1\n",
            "Epoch 2, batch 10/372\n",
            "Epoch 2, batch 20/372\n",
            "Epoch 2, batch 30/372\n",
            "Epoch 2, batch 40/372\n",
            "Epoch 2, batch 50/372\n",
            "Epoch 2, batch 60/372\n",
            "Epoch 2, batch 70/372\n",
            "Epoch 2, batch 80/372\n",
            "Epoch 2, batch 90/372\n",
            "Epoch 2, batch 100/372\n",
            "Epoch 2, batch 110/372\n",
            "Epoch 2, batch 120/372\n",
            "Epoch 2, batch 130/372\n",
            "Epoch 2, batch 140/372\n",
            "Epoch 2, batch 150/372\n",
            "Epoch 2, batch 160/372\n",
            "Epoch 2, batch 170/372\n",
            "Epoch 2, batch 180/372\n",
            "Epoch 2, batch 190/372\n",
            "Epoch 2, batch 200/372\n",
            "Epoch 2, batch 210/372\n",
            "Epoch 2, batch 220/372\n",
            "Epoch 2, batch 230/372\n",
            "Epoch 2, batch 240/372\n",
            "Epoch 2, batch 250/372\n",
            "Epoch 2, batch 260/372\n",
            "Epoch 2, batch 270/372\n",
            "Epoch 2, batch 280/372\n",
            "Epoch 2, batch 290/372\n",
            "Epoch 2, batch 300/372\n",
            "Epoch 2, batch 310/372\n",
            "Epoch 2, batch 320/372\n",
            "Epoch 2, batch 330/372\n",
            "Epoch 2, batch 340/372\n",
            "Epoch 2, batch 350/372\n",
            "Epoch 2, batch 360/372\n",
            "Epoch 2, batch 370/372\n",
            "Epoch 2, batch 372/372\n",
            "Epoch 2, Training Loss: 1.0907995383585654\n",
            "Validation Loss: 1.0879741320534357\n",
            "Model saved to: /content/drive/MyDrive/datasets/barlowtwins-unfrozen-2.pth\n",
            "Epoch execution time: 33 minutes!\n",
            "Remaining: 8 epochs, about 264 minutes!\n",
            "Best model is: 2\n",
            "Epoch 3, batch 10/372\n",
            "Epoch 3, batch 20/372\n",
            "Epoch 3, batch 30/372\n",
            "Epoch 3, batch 40/372\n",
            "Epoch 3, batch 50/372\n",
            "Epoch 3, batch 60/372\n",
            "Epoch 3, batch 70/372\n",
            "Epoch 3, batch 80/372\n",
            "Epoch 3, batch 90/372\n",
            "Epoch 3, batch 100/372\n",
            "Epoch 3, batch 110/372\n",
            "Epoch 3, batch 120/372\n",
            "Epoch 3, batch 130/372\n",
            "Epoch 3, batch 140/372\n",
            "Epoch 3, batch 150/372\n",
            "Epoch 3, batch 160/372\n",
            "Epoch 3, batch 170/372\n",
            "Epoch 3, batch 180/372\n",
            "Epoch 3, batch 190/372\n",
            "Epoch 3, batch 200/372\n",
            "Epoch 3, batch 210/372\n",
            "Epoch 3, batch 220/372\n",
            "Epoch 3, batch 230/372\n",
            "Epoch 3, batch 240/372\n",
            "Epoch 3, batch 250/372\n",
            "Epoch 3, batch 260/372\n",
            "Epoch 3, batch 270/372\n",
            "Epoch 3, batch 280/372\n",
            "Epoch 3, batch 290/372\n",
            "Epoch 3, batch 300/372\n",
            "Epoch 3, batch 310/372\n",
            "Epoch 3, batch 320/372\n",
            "Epoch 3, batch 330/372\n",
            "Epoch 3, batch 340/372\n",
            "Epoch 3, batch 350/372\n",
            "Epoch 3, batch 360/372\n",
            "Epoch 3, batch 370/372\n",
            "Epoch 3, batch 372/372\n",
            "Epoch 3, Training Loss: 1.0596383907782134\n",
            "Validation Loss: 1.0545704913517786\n",
            "Model saved to: /content/drive/MyDrive/datasets/barlowtwins-unfrozen-3.pth\n",
            "Epoch execution time: 33 minutes!\n",
            "Remaining: 7 epochs, about 231 minutes!\n",
            "Best model is: 3\n",
            "Epoch 4, batch 10/372\n",
            "Epoch 4, batch 20/372\n",
            "Epoch 4, batch 30/372\n",
            "Epoch 4, batch 40/372\n",
            "Epoch 4, batch 50/372\n",
            "Epoch 4, batch 60/372\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-ab747bf93b33>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Training loop\n",
        "num_epochs=10\n",
        "print_every=10\n",
        "best_model = 0\n",
        "best_val_loss_avg=float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    total_batches = len(loader)\n",
        "    for batch_idx, (images, labels) in enumerate(loader):\n",
        "        if (batch_idx + 1) % print_every == 0 or (batch_idx + 1) == total_batches:\n",
        "          print(f\"Epoch {epoch+1}, batch {batch_idx+1}/{total_batches}\")\n",
        "        optimizer.zero_grad()\n",
        "        labels = labels.squeeze(1)\n",
        "        # print(f\"images shape: {images.shape}\")\n",
        "        outputs = model(images)\n",
        "        # print(f\"outputs shape: {outputs.shape}\")\n",
        "        labels = labels.long()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Training Loss: {running_loss / len(loader)}\")\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_running_loss = 0.0\n",
        "    val_total_batches = len(loader_val)\n",
        "\n",
        "    with torch.no_grad():  # Turn off gradient calculation during validation\n",
        "        for batch_idx, (val_images, val_labels) in enumerate(loader_val):\n",
        "            val_labels = val_labels.squeeze(1)\n",
        "            val_outputs = model(val_images)\n",
        "            val_labels = val_labels.long()\n",
        "            val_loss = criterion(val_outputs, val_labels)\n",
        "            val_running_loss += val_loss.item()\n",
        "\n",
        "    val_loss_avg = val_running_loss / len(loader_val)\n",
        "    print(f\"Validation Loss: {val_loss_avg}\")\n",
        "    model_save_path = f\"/content/drive/MyDrive/datasets/barlowtwins-unfrozen-{epoch+1}.pth\"\n",
        "    torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': criterion,\n",
        "                }, model_save_path)\n",
        "    print(f\"Model saved to: {model_save_path}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    execution_time = int(execution_time/60)\n",
        "    print(\"Epoch execution time:\", execution_time, \"minutes!\")\n",
        "    print(f\"Remaining: {(num_epochs-epoch-1)} epochs, about {(num_epochs-epoch-1)*execution_time} minutes!\")\n",
        "\n",
        "    if (val_loss_avg<best_val_loss_avg):\n",
        "      best_val_loss_avg=val_loss_avg\n",
        "      best_model=epoch+1\n",
        "    print(f\"Best model is: {best_model}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KY7CjMDUQxuD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}