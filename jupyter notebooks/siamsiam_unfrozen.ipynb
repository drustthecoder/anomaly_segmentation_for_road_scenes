{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6bcqDGPelrF",
        "outputId": "31bcfc80-8b92-4a6e-cd7f-de8f5807bd4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMGowi4LfhAV",
        "outputId": "61c5c564-add8-4610-f28a-f5012581c138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 3 minutes\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "!mkdir cityscapes\n",
        "!unzip -qo /content/drive/MyDrive/datasets/leftImg8bit_trainvaltest.zip -d /content/cityscapes\n",
        "!unzip -qo /content/drive/MyDrive/datasets/gtFine_trainvaltest.zip -d /content/cityscapes\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "execution_time = int(execution_time/60)\n",
        "print(\"Execution time:\", execution_time, \"minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3ilxErqiGNF",
        "outputId": "89e17325-34e0-4af2-f024-294071b4f5a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.6/473.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q visdom ood_metrics cityscapesscripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9524JHa5P3AI",
        "outputId": "37e0f4be-1830-4247-df07-f4236d186981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cityscapesScripts'...\n",
            "remote: Enumerating objects: 648, done.\u001b[K\n",
            "remote: Counting objects: 100% (221/221), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 648 (delta 184), reused 165 (delta 155), pack-reused 427\u001b[K\n",
            "Receiving objects: 100% (648/648), 796.28 KiB | 8.47 MiB/s, done.\n",
            "Resolving deltas: 100% (370/370), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mcordts/cityscapesScripts.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk-D7IPLiJJF",
        "outputId": "0367c3e8-dfc3-45a1-ba21-fa9eb7346126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 5000 annotation files\n",
            "Progress: 100.0 % Execution time: 3 minutes\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "import os\n",
        "os.environ[\"CITYSCAPES_DATASET\"] = \"/content/cityscapes\"\n",
        "!python cityscapesScripts/cityscapesscripts/preparation/createTrainIdLabelImgs.py\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "execution_time = int(execution_time/60)\n",
        "print(\"Execution time:\", execution_time, \"minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sncgFrG3XQ-I",
        "outputId": "f800a754-0d34-47e0-b64c-7c218b4226d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'anomaly-segmentation-for-road-scenes'...\n",
            "remote: Enumerating objects: 806, done.\u001b[K\n",
            "remote: Counting objects: 100% (125/125), done.\u001b[K\n",
            "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "remote: Total 806 (delta 71), reused 95 (delta 43), pack-reused 681\u001b[K\n",
            "Receiving objects: 100% (806/806), 562.14 MiB | 23.73 MiB/s, done.\n",
            "Resolving deltas: 100% (189/189), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/shayanit/anomaly-segmentation-for-road-scenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TA9TU1JM6e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21ee897d-ac11-432c-8f92-f66d7aec8f58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/anomaly-segmentation-for-road-scenes/train\n"
          ]
        }
      ],
      "source": [
        "%cd /content/anomaly-segmentation-for-road-scenes/train\n",
        "from main import MyCoTransformExtension\n",
        "from dataset import cityscapes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "simsiam_resnet = models.resnet50(pretrained=False)\n",
        "# checkpoint = torch.load('/content/drive/MyDrive/datasets/moco_v2_800ep_pretrain.pth.tar')\n",
        "# checkpoint_dict = checkpoint['state_dict']\n",
        "# simsiam_resnet.load_state_dict(checkpoint_dict, strict=False)\n",
        "for param in simsiam_resnet.parameters():\n",
        "    param.requires_grad = True #UNFREEZE\n",
        "simsiam_resnet = nn.Sequential(*list(simsiam_resnet.children())[:-2])\n",
        "num_classes = 20\n",
        "segmentation_head = nn.Conv2d(2048, num_classes, kernel_size=1)\n",
        "upsample = nn.Upsample(size=(224,224), mode='bilinear', align_corners=False)\n",
        "SimSiamModel = nn.Sequential(simsiam_resnet, segmentation_head, upsample)"
      ],
      "metadata": {
        "id": "QfrbgNDGZpyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bcb463f-1fba-494f-ecae-e7c97379336d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5F6Dqm_gNKh",
        "outputId": "9ec102b0-995e-4822-8890-329ab25be7e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cityscapes/leftImg8bit/train\n",
            "/content/cityscapes/leftImg8bit/val\n",
            "torch.Size([3, 224, 224])\n",
            "torch.Size([1, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.hub import load as hub_load\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load Cityscapes dataset\n",
        "datadir = '/content/cityscapes'\n",
        "co_transform = MyCoTransformExtension(False, augment=True)\n",
        "co_transform_val = MyCoTransformExtension(False, augment=False)\n",
        "dataset_train = cityscapes(datadir, co_transform, 'train')\n",
        "dataset_val = cityscapes(datadir, co_transform_val, 'val')\n",
        "\n",
        "loader = DataLoader(dataset_train, num_workers=2, batch_size=8, shuffle=True)\n",
        "loader_val = DataLoader(dataset_val, num_workers=2, batch_size=8, shuffle=False)\n",
        "\n",
        "print(dataset_train[0][0].shape)\n",
        "print(dataset_train[0][1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnmHwm5nyxlW",
        "outputId": "4e7646ff-92b0-4207-c6f3-232d5fd94678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqyT8yIzgW25"
      },
      "source": [
        "#Continue train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1PKyVlF53jH"
      },
      "outputs": [],
      "source": [
        "#Continue train\n",
        "import time\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimSiamModel\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Choose optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Load the model\n",
        "checkpoint = torch.load('/content/drive/MyDrive/datasets/simsiam-frozen.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "loss = checkpoint['loss']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(model.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKyMWeQrx0SA",
        "outputId": "f0b17a7d-9734-4275-c055-546cc597376b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHN0-JeEghRe"
      },
      "source": [
        "#Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FYT3KC7fGtu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b25a595-6981-40c5-8a16-6e0cbc1b7846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, batch 10/372\n",
            "Epoch 1, batch 20/372\n",
            "Epoch 1, batch 30/372\n",
            "Epoch 1, batch 40/372\n",
            "Epoch 1, batch 50/372\n",
            "Epoch 1, batch 60/372\n",
            "Epoch 1, batch 70/372\n",
            "Epoch 1, batch 80/372\n",
            "Epoch 1, batch 90/372\n",
            "Epoch 1, batch 100/372\n",
            "Epoch 1, batch 110/372\n",
            "Epoch 1, batch 120/372\n",
            "Epoch 1, batch 130/372\n",
            "Epoch 1, batch 140/372\n",
            "Epoch 1, batch 150/372\n",
            "Epoch 1, batch 160/372\n",
            "Epoch 1, batch 170/372\n",
            "Epoch 1, batch 180/372\n",
            "Epoch 1, batch 190/372\n",
            "Epoch 1, batch 200/372\n",
            "Epoch 1, batch 210/372\n",
            "Epoch 1, batch 220/372\n",
            "Epoch 1, batch 230/372\n",
            "Epoch 1, batch 240/372\n",
            "Epoch 1, batch 250/372\n",
            "Epoch 1, batch 260/372\n",
            "Epoch 1, batch 270/372\n",
            "Epoch 1, batch 280/372\n",
            "Epoch 1, batch 290/372\n",
            "Epoch 1, batch 300/372\n",
            "Epoch 1, batch 310/372\n",
            "Epoch 1, batch 320/372\n",
            "Epoch 1, batch 330/372\n",
            "Epoch 1, batch 340/372\n",
            "Epoch 1, batch 350/372\n",
            "Epoch 1, batch 360/372\n",
            "Epoch 1, batch 370/372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, batch 372/372\n",
            "Epoch 1, Training Loss: 1.3096074631778143\n",
            "Validation Loss: 1.2598374627885365\n",
            "Model saved to: /content/drive/MyDrive/datasets/simsiam-unfrozen-1.pth\n",
            "Epoch execution time: 6 minutes!\n",
            "Remaining: 9 epochs, about 54 minutes!\n",
            "Best model is: 1\n",
            "Epoch 2, batch 10/372\n",
            "Epoch 2, batch 20/372\n",
            "Epoch 2, batch 30/372\n",
            "Epoch 2, batch 40/372\n",
            "Epoch 2, batch 50/372\n",
            "Epoch 2, batch 60/372\n",
            "Epoch 2, batch 70/372\n",
            "Epoch 2, batch 80/372\n",
            "Epoch 2, batch 90/372\n",
            "Epoch 2, batch 100/372\n",
            "Epoch 2, batch 110/372\n",
            "Epoch 2, batch 120/372\n",
            "Epoch 2, batch 130/372\n",
            "Epoch 2, batch 140/372\n",
            "Epoch 2, batch 150/372\n",
            "Epoch 2, batch 160/372\n",
            "Epoch 2, batch 170/372\n",
            "Epoch 2, batch 180/372\n",
            "Epoch 2, batch 190/372\n",
            "Epoch 2, batch 200/372\n",
            "Epoch 2, batch 210/372\n",
            "Epoch 2, batch 220/372\n",
            "Epoch 2, batch 230/372\n",
            "Epoch 2, batch 240/372\n",
            "Epoch 2, batch 250/372\n",
            "Epoch 2, batch 260/372\n",
            "Epoch 2, batch 270/372\n",
            "Epoch 2, batch 280/372\n",
            "Epoch 2, batch 290/372\n",
            "Epoch 2, batch 300/372\n",
            "Epoch 2, batch 310/372\n",
            "Epoch 2, batch 320/372\n",
            "Epoch 2, batch 330/372\n",
            "Epoch 2, batch 340/372\n",
            "Epoch 2, batch 350/372\n",
            "Epoch 2, batch 360/372\n",
            "Epoch 2, batch 370/372\n",
            "Epoch 2, batch 372/372\n",
            "Epoch 2, Training Loss: 1.1889669781410566\n",
            "Validation Loss: 1.1941824479708596\n",
            "Model saved to: /content/drive/MyDrive/datasets/simsiam-unfrozen-2.pth\n",
            "Epoch execution time: 6 minutes!\n",
            "Remaining: 8 epochs, about 48 minutes!\n",
            "Best model is: 2\n",
            "Epoch 3, batch 10/372\n",
            "Epoch 3, batch 20/372\n",
            "Epoch 3, batch 30/372\n",
            "Epoch 3, batch 40/372\n",
            "Epoch 3, batch 50/372\n",
            "Epoch 3, batch 60/372\n",
            "Epoch 3, batch 70/372\n",
            "Epoch 3, batch 80/372\n",
            "Epoch 3, batch 90/372\n",
            "Epoch 3, batch 100/372\n",
            "Epoch 3, batch 110/372\n",
            "Epoch 3, batch 120/372\n",
            "Epoch 3, batch 130/372\n",
            "Epoch 3, batch 140/372\n",
            "Epoch 3, batch 150/372\n",
            "Epoch 3, batch 160/372\n",
            "Epoch 3, batch 170/372\n",
            "Epoch 3, batch 180/372\n",
            "Epoch 3, batch 190/372\n",
            "Epoch 3, batch 200/372\n",
            "Epoch 3, batch 210/372\n",
            "Epoch 3, batch 220/372\n",
            "Epoch 3, batch 230/372\n",
            "Epoch 3, batch 240/372\n",
            "Epoch 3, batch 250/372\n",
            "Epoch 3, batch 260/372\n",
            "Epoch 3, batch 270/372\n",
            "Epoch 3, batch 280/372\n",
            "Epoch 3, batch 290/372\n",
            "Epoch 3, batch 300/372\n",
            "Epoch 3, batch 310/372\n",
            "Epoch 3, batch 320/372\n",
            "Epoch 3, batch 330/372\n",
            "Epoch 3, batch 340/372\n",
            "Epoch 3, batch 350/372\n",
            "Epoch 3, batch 360/372\n",
            "Epoch 3, batch 370/372\n",
            "Epoch 3, batch 372/372\n",
            "Epoch 3, Training Loss: 1.134450547637478\n",
            "Validation Loss: 1.1576437108100406\n",
            "Model saved to: /content/drive/MyDrive/datasets/simsiam-unfrozen-3.pth\n",
            "Epoch execution time: 6 minutes!\n",
            "Remaining: 7 epochs, about 42 minutes!\n",
            "Best model is: 3\n",
            "Epoch 4, batch 10/372\n",
            "Epoch 4, batch 20/372\n",
            "Epoch 4, batch 30/372\n",
            "Epoch 4, batch 40/372\n",
            "Epoch 4, batch 50/372\n",
            "Epoch 4, batch 60/372\n",
            "Epoch 4, batch 70/372\n",
            "Epoch 4, batch 80/372\n",
            "Epoch 4, batch 90/372\n",
            "Epoch 4, batch 100/372\n",
            "Epoch 4, batch 110/372\n",
            "Epoch 4, batch 120/372\n",
            "Epoch 4, batch 130/372\n",
            "Epoch 4, batch 140/372\n",
            "Epoch 4, batch 150/372\n",
            "Epoch 4, batch 160/372\n",
            "Epoch 4, batch 170/372\n",
            "Epoch 4, batch 180/372\n",
            "Epoch 4, batch 190/372\n",
            "Epoch 4, batch 200/372\n",
            "Epoch 4, batch 210/372\n",
            "Epoch 4, batch 220/372\n",
            "Epoch 4, batch 230/372\n",
            "Epoch 4, batch 240/372\n",
            "Epoch 4, batch 250/372\n",
            "Epoch 4, batch 260/372\n",
            "Epoch 4, batch 270/372\n",
            "Epoch 4, batch 280/372\n",
            "Epoch 4, batch 290/372\n",
            "Epoch 4, batch 300/372\n",
            "Epoch 4, batch 310/372\n",
            "Epoch 4, batch 320/372\n",
            "Epoch 4, batch 330/372\n",
            "Epoch 4, batch 340/372\n",
            "Epoch 4, batch 350/372\n",
            "Epoch 4, batch 360/372\n",
            "Epoch 4, batch 370/372\n",
            "Epoch 4, batch 372/372\n",
            "Epoch 4, Training Loss: 1.0898319271302992\n",
            "Validation Loss: 1.0977552041174874\n",
            "Model saved to: /content/drive/MyDrive/datasets/simsiam-unfrozen-4.pth\n",
            "Epoch execution time: 6 minutes!\n",
            "Remaining: 6 epochs, about 36 minutes!\n",
            "Best model is: 4\n",
            "Epoch 5, batch 10/372\n",
            "Epoch 5, batch 20/372\n",
            "Epoch 5, batch 30/372\n",
            "Epoch 5, batch 40/372\n",
            "Epoch 5, batch 50/372\n",
            "Epoch 5, batch 60/372\n",
            "Epoch 5, batch 70/372\n",
            "Epoch 5, batch 80/372\n",
            "Epoch 5, batch 90/372\n",
            "Epoch 5, batch 100/372\n",
            "Epoch 5, batch 110/372\n",
            "Epoch 5, batch 120/372\n",
            "Epoch 5, batch 130/372\n",
            "Epoch 5, batch 140/372\n",
            "Epoch 5, batch 150/372\n",
            "Epoch 5, batch 160/372\n",
            "Epoch 5, batch 170/372\n",
            "Epoch 5, batch 180/372\n",
            "Epoch 5, batch 190/372\n",
            "Epoch 5, batch 200/372\n",
            "Epoch 5, batch 210/372\n",
            "Epoch 5, batch 220/372\n",
            "Epoch 5, batch 230/372\n",
            "Epoch 5, batch 240/372\n",
            "Epoch 5, batch 250/372\n",
            "Epoch 5, batch 260/372\n",
            "Epoch 5, batch 270/372\n",
            "Epoch 5, batch 280/372\n",
            "Epoch 5, batch 290/372\n",
            "Epoch 5, batch 300/372\n",
            "Epoch 5, batch 310/372\n",
            "Epoch 5, batch 320/372\n",
            "Epoch 5, batch 330/372\n",
            "Epoch 5, batch 340/372\n",
            "Epoch 5, batch 350/372\n",
            "Epoch 5, batch 360/372\n",
            "Epoch 5, batch 370/372\n",
            "Epoch 5, batch 372/372\n",
            "Epoch 5, Training Loss: 1.0385559526502446\n",
            "Validation Loss: 1.0478849060951718\n",
            "Model saved to: /content/drive/MyDrive/datasets/simsiam-unfrozen-5.pth\n",
            "Epoch execution time: 5 minutes!\n",
            "Remaining: 5 epochs, about 25 minutes!\n",
            "Best model is: 5\n",
            "Epoch 6, batch 10/372\n",
            "Epoch 6, batch 20/372\n",
            "Epoch 6, batch 30/372\n",
            "Epoch 6, batch 40/372\n",
            "Epoch 6, batch 50/372\n",
            "Epoch 6, batch 60/372\n",
            "Epoch 6, batch 70/372\n",
            "Epoch 6, batch 80/372\n",
            "Epoch 6, batch 90/372\n",
            "Epoch 6, batch 100/372\n",
            "Epoch 6, batch 110/372\n",
            "Epoch 6, batch 120/372\n",
            "Epoch 6, batch 130/372\n",
            "Epoch 6, batch 140/372\n",
            "Epoch 6, batch 150/372\n",
            "Epoch 6, batch 160/372\n",
            "Epoch 6, batch 170/372\n",
            "Epoch 6, batch 180/372\n",
            "Epoch 6, batch 190/372\n",
            "Epoch 6, batch 200/372\n",
            "Epoch 6, batch 210/372\n",
            "Epoch 6, batch 220/372\n",
            "Epoch 6, batch 230/372\n",
            "Epoch 6, batch 240/372\n",
            "Epoch 6, batch 250/372\n",
            "Epoch 6, batch 260/372\n",
            "Epoch 6, batch 270/372\n",
            "Epoch 6, batch 280/372\n",
            "Epoch 6, batch 290/372\n",
            "Epoch 6, batch 300/372\n",
            "Epoch 6, batch 310/372\n",
            "Epoch 6, batch 320/372\n",
            "Epoch 6, batch 330/372\n",
            "Epoch 6, batch 340/372\n",
            "Epoch 6, batch 350/372\n",
            "Epoch 6, batch 360/372\n",
            "Epoch 6, batch 370/372\n",
            "Epoch 6, batch 372/372\n",
            "Epoch 6, Training Loss: 0.9990651232580985\n",
            "Validation Loss: 1.0202317635218303\n",
            "Model saved to: /content/drive/MyDrive/datasets/simsiam-unfrozen-6.pth\n",
            "Epoch execution time: 5 minutes!\n",
            "Remaining: 4 epochs, about 20 minutes!\n",
            "Best model is: 6\n",
            "Epoch 7, batch 10/372\n",
            "Epoch 7, batch 20/372\n",
            "Epoch 7, batch 30/372\n",
            "Epoch 7, batch 40/372\n",
            "Epoch 7, batch 50/372\n",
            "Epoch 7, batch 60/372\n",
            "Epoch 7, batch 70/372\n",
            "Epoch 7, batch 80/372\n",
            "Epoch 7, batch 90/372\n",
            "Epoch 7, batch 100/372\n",
            "Epoch 7, batch 110/372\n",
            "Epoch 7, batch 120/372\n",
            "Epoch 7, batch 130/372\n",
            "Epoch 7, batch 140/372\n",
            "Epoch 7, batch 150/372\n",
            "Epoch 7, batch 160/372\n",
            "Epoch 7, batch 170/372\n",
            "Epoch 7, batch 180/372\n",
            "Epoch 7, batch 190/372\n",
            "Epoch 7, batch 200/372\n",
            "Epoch 7, batch 210/372\n",
            "Epoch 7, batch 220/372\n",
            "Epoch 7, batch 230/372\n",
            "Epoch 7, batch 240/372\n",
            "Epoch 7, batch 250/372\n",
            "Epoch 7, batch 260/372\n",
            "Epoch 7, batch 270/372\n",
            "Epoch 7, batch 280/372\n",
            "Epoch 7, batch 290/372\n",
            "Epoch 7, batch 300/372\n",
            "Epoch 7, batch 310/372\n",
            "Epoch 7, batch 320/372\n",
            "Epoch 7, batch 330/372\n",
            "Epoch 7, batch 340/372\n",
            "Epoch 7, batch 350/372\n",
            "Epoch 7, batch 360/372\n",
            "Epoch 7, batch 370/372\n",
            "Epoch 7, batch 372/372\n",
            "Epoch 7, Training Loss: 0.9710246878926472\n",
            "Validation Loss: 1.0184732685013422\n",
            "Model saved to: /content/drive/MyDrive/datasets/simsiam-unfrozen-7.pth\n",
            "Epoch execution time: 6 minutes!\n",
            "Remaining: 3 epochs, about 18 minutes!\n",
            "Best model is: 7\n",
            "Epoch 8, batch 10/372\n",
            "Epoch 8, batch 20/372\n",
            "Epoch 8, batch 30/372\n",
            "Epoch 8, batch 40/372\n",
            "Epoch 8, batch 50/372\n",
            "Epoch 8, batch 60/372\n",
            "Epoch 8, batch 70/372\n",
            "Epoch 8, batch 80/372\n",
            "Epoch 8, batch 90/372\n",
            "Epoch 8, batch 100/372\n",
            "Epoch 8, batch 110/372\n",
            "Epoch 8, batch 120/372\n",
            "Epoch 8, batch 130/372\n",
            "Epoch 8, batch 140/372\n",
            "Epoch 8, batch 150/372\n",
            "Epoch 8, batch 160/372\n",
            "Epoch 8, batch 170/372\n",
            "Epoch 8, batch 180/372\n",
            "Epoch 8, batch 190/372\n",
            "Epoch 8, batch 200/372\n",
            "Epoch 8, batch 210/372\n",
            "Epoch 8, batch 220/372\n",
            "Epoch 8, batch 230/372\n",
            "Epoch 8, batch 240/372\n",
            "Epoch 8, batch 250/372\n",
            "Epoch 8, batch 260/372\n",
            "Epoch 8, batch 270/372\n",
            "Epoch 8, batch 280/372\n",
            "Epoch 8, batch 290/372\n",
            "Epoch 8, batch 300/372\n",
            "Epoch 8, batch 310/372\n",
            "Epoch 8, batch 320/372\n",
            "Epoch 8, batch 330/372\n",
            "Epoch 8, batch 340/372\n",
            "Epoch 8, batch 350/372\n",
            "Epoch 8, batch 360/372\n",
            "Epoch 8, batch 370/372\n",
            "Epoch 8, batch 372/372\n",
            "Epoch 8, Training Loss: 0.9432547579529464\n",
            "Validation Loss: 1.0188188959681799\n",
            "Model saved to: /content/drive/MyDrive/datasets/simsiam-unfrozen-8.pth\n",
            "Epoch execution time: 5 minutes!\n",
            "Remaining: 2 epochs, about 10 minutes!\n",
            "Best model is: 7\n",
            "Epoch 9, batch 10/372\n",
            "Epoch 9, batch 20/372\n",
            "Epoch 9, batch 30/372\n",
            "Epoch 9, batch 40/372\n",
            "Epoch 9, batch 50/372\n",
            "Epoch 9, batch 60/372\n",
            "Epoch 9, batch 70/372\n",
            "Epoch 9, batch 80/372\n",
            "Epoch 9, batch 90/372\n",
            "Epoch 9, batch 100/372\n",
            "Epoch 9, batch 110/372\n",
            "Epoch 9, batch 120/372\n",
            "Epoch 9, batch 130/372\n",
            "Epoch 9, batch 140/372\n",
            "Epoch 9, batch 150/372\n",
            "Epoch 9, batch 160/372\n",
            "Epoch 9, batch 170/372\n",
            "Epoch 9, batch 180/372\n",
            "Epoch 9, batch 190/372\n",
            "Epoch 9, batch 200/372\n",
            "Epoch 9, batch 210/372\n",
            "Epoch 9, batch 220/372\n",
            "Epoch 9, batch 230/372\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f9ddb06fd216>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtotal_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtotal_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Training loop\n",
        "num_epochs=10\n",
        "print_every=10\n",
        "best_model = 0\n",
        "best_val_loss_avg=float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    total_batches = len(loader)\n",
        "    for batch_idx, (images, labels) in enumerate(loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        if (batch_idx + 1) % print_every == 0 or (batch_idx + 1) == total_batches:\n",
        "          print(f\"Epoch {epoch+1}, batch {batch_idx+1}/{total_batches}\")\n",
        "        optimizer.zero_grad()\n",
        "        labels = labels.squeeze(1)\n",
        "        # print(f\"images shape: {images.shape}\")\n",
        "        outputs = model(images)\n",
        "        # print(f\"outputs shape: {outputs.shape}\")\n",
        "        labels = labels.long()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Training Loss: {running_loss / len(loader)}\")\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_running_loss = 0.0\n",
        "    val_total_batches = len(loader_val)\n",
        "\n",
        "    with torch.no_grad():  # Turn off gradient calculation during validation\n",
        "        for batch_idx, (val_images, val_labels) in enumerate(loader_val):\n",
        "            val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
        "            val_labels = val_labels.squeeze(1)\n",
        "            val_outputs = model(val_images)\n",
        "            val_labels = val_labels.long()\n",
        "            val_loss = criterion(val_outputs, val_labels)\n",
        "            val_running_loss += val_loss.item()\n",
        "\n",
        "    val_loss_avg = val_running_loss / len(loader_val)\n",
        "    print(f\"Validation Loss: {val_loss_avg}\")\n",
        "    model_save_path = f\"/content/drive/MyDrive/datasets/simsiam-unfrozen-{epoch+1}.pth\"\n",
        "    torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': criterion,\n",
        "                }, model_save_path)\n",
        "    print(f\"Model saved to: {model_save_path}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    execution_time = int(execution_time/60)\n",
        "    print(\"Epoch execution time:\", execution_time, \"minutes!\")\n",
        "    print(f\"Remaining: {(num_epochs-epoch-1)} epochs, about {(num_epochs-epoch-1)*execution_time} minutes!\")\n",
        "\n",
        "    if (val_loss_avg<best_val_loss_avg):\n",
        "      best_val_loss_avg=val_loss_avg\n",
        "      best_model=epoch+1\n",
        "    print(f\"Best model is: {best_model}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KY7CjMDUQxuD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}