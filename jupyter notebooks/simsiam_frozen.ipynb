{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6bcqDGPelrF",
        "outputId": "c30ec80e-5860-439e-9dd0-03a95b69b766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMGowi4LfhAV",
        "outputId": "e6aa1ece-1efe-468c-acf5-a7ca12ed0a4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 6 minutes\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "!mkdir cityscapes\n",
        "!unzip -qo /content/drive/MyDrive/datasets/leftImg8bit_trainvaltest.zip -d /content/cityscapes\n",
        "!unzip -qo /content/drive/MyDrive/datasets/gtFine_trainvaltest.zip -d /content/cityscapes\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "execution_time = int(execution_time/60)\n",
        "print(\"Execution time:\", execution_time, \"minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3ilxErqiGNF",
        "outputId": "1574c497-56f8-4a53-db97-1e018969deae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.4 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.6/473.6 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q visdom ood_metrics cityscapesscripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9524JHa5P3AI",
        "outputId": "f84a8017-b86b-4b80-cf7b-38d90e427b31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cityscapesScripts'...\n",
            "remote: Enumerating objects: 648, done.\u001b[K\n",
            "remote: Counting objects: 100% (221/221), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 648 (delta 184), reused 165 (delta 155), pack-reused 427\u001b[K\n",
            "Receiving objects: 100% (648/648), 796.28 KiB | 11.54 MiB/s, done.\n",
            "Resolving deltas: 100% (370/370), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mcordts/cityscapesScripts.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk-D7IPLiJJF",
        "outputId": "15045391-94db-476f-f5e0-741c2e3c8b36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 5000 annotation files\n",
            "Progress: 100.0 % Execution time: 2 minutes\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "import os\n",
        "os.environ[\"CITYSCAPES_DATASET\"] = \"/content/cityscapes\"\n",
        "!python cityscapesScripts/cityscapesscripts/preparation/createTrainIdLabelImgs.py\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "execution_time = int(execution_time/60)\n",
        "print(\"Execution time:\", execution_time, \"minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sncgFrG3XQ-I",
        "outputId": "fd2d39f2-7381-4562-af47-48aa7c9a067c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'anomaly-segmentation-for-road-scenes'...\n",
            "remote: Enumerating objects: 806, done.\u001b[K\n",
            "remote: Counting objects: 100% (125/125), done.\u001b[K\n",
            "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "remote: Total 806 (delta 71), reused 95 (delta 43), pack-reused 681\u001b[K\n",
            "Receiving objects: 100% (806/806), 562.14 MiB | 14.25 MiB/s, done.\n",
            "Resolving deltas: 100% (189/189), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/shayanit/anomaly-segmentation-for-road-scenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TA9TU1JM6e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "809fa3a4-7477-4353-e44b-3335b6bc31ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/anomaly-segmentation-for-road-scenes/train\n"
          ]
        }
      ],
      "source": [
        "%cd /content/anomaly-segmentation-for-road-scenes/train\n",
        "from main import MyCoTransformExtension\n",
        "from dataset import cityscapes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "simsiam = models.resnet50(pretrained=False)\n",
        "checkpoint = torch.load('/content/drive/MyDrive/datasets/simsiam_checkpoint_0099.pth.tar')\n",
        "checkpoint_dict = checkpoint['state_dict']\n",
        "simsiam.load_state_dict(checkpoint_dict, strict=False)\n",
        "for param in simsiam.parameters():\n",
        "    param.requires_grad = False #FREEZE\n",
        "simsiam = nn.Sequential(*list(simsiam.children())[:-2])\n",
        "num_classes = 20\n",
        "segmentation_head = nn.Conv2d(2048, num_classes, kernel_size=1)\n",
        "upsample = nn.Upsample(size=(224,224), mode='bilinear', align_corners=False)\n",
        "SimSiamModel = nn.Sequential(simsiam, segmentation_head, upsample)"
      ],
      "metadata": {
        "id": "QfrbgNDGZpyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb6d0f0a-d595-4abe-a4f6-9b5936a14e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "AHIH9Q7tyOj8",
        "outputId": "b689ec91-fcdf-4064-d09c-a7e3f4393702",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5F6Dqm_gNKh",
        "outputId": "17da4ba0-2c6a-4df9-cb56-e3ea44788ad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cityscapes/leftImg8bit/train\n",
            "/content/cityscapes/leftImg8bit/val\n",
            "torch.Size([3, 224, 224])\n",
            "torch.Size([1, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.hub import load as hub_load\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load Cityscapes dataset\n",
        "datadir = '/content/cityscapes'\n",
        "co_transform = MyCoTransformExtension(False, augment=True)\n",
        "co_transform_val = MyCoTransformExtension(False, augment=False)\n",
        "dataset_train = cityscapes(datadir, co_transform, 'train')\n",
        "dataset_val = cityscapes(datadir, co_transform_val, 'val')\n",
        "\n",
        "loader = DataLoader(dataset_train, num_workers=2, batch_size=8, shuffle=True)\n",
        "loader_val = DataLoader(dataset_val, num_workers=2, batch_size=8, shuffle=False)\n",
        "\n",
        "print(dataset_train[0][0].shape)\n",
        "print(dataset_train[0][1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHN0-JeEghRe"
      },
      "source": [
        "#Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FYT3KC7fGtu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79305c7e-86f5-4666-88a9-fed1f04da860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, batch 10/372\n",
            "Epoch 1, batch 20/372\n",
            "Epoch 1, batch 30/372\n",
            "Epoch 1, batch 40/372\n",
            "Epoch 1, batch 50/372\n",
            "Epoch 1, batch 60/372\n",
            "Epoch 1, batch 70/372\n",
            "Epoch 1, batch 80/372\n",
            "Epoch 1, batch 90/372\n",
            "Epoch 1, batch 100/372\n",
            "Epoch 1, batch 110/372\n",
            "Epoch 1, batch 120/372\n",
            "Epoch 1, batch 130/372\n",
            "Epoch 1, batch 140/372\n",
            "Epoch 1, batch 150/372\n",
            "Epoch 1, batch 160/372\n",
            "Epoch 1, batch 170/372\n",
            "Epoch 1, batch 180/372\n",
            "Epoch 1, batch 190/372\n",
            "Epoch 1, batch 200/372\n",
            "Epoch 1, batch 210/372\n",
            "Epoch 1, batch 220/372\n",
            "Epoch 1, batch 230/372\n",
            "Epoch 1, batch 240/372\n",
            "Epoch 1, batch 250/372\n",
            "Epoch 1, batch 260/372\n",
            "Epoch 1, batch 270/372\n",
            "Epoch 1, batch 280/372\n",
            "Epoch 1, batch 290/372\n",
            "Epoch 1, batch 300/372\n",
            "Epoch 1, batch 310/372\n",
            "Epoch 1, batch 320/372\n",
            "Epoch 1, batch 330/372\n",
            "Epoch 1, batch 340/372\n",
            "Epoch 1, batch 350/372\n",
            "Epoch 1, batch 360/372\n",
            "Epoch 1, batch 370/372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, batch 372/372\n",
            "Epoch 1, Training Loss: 1.6144416556563428\n",
            "Validation Loss: 1.5557471948956687\n",
            "Model saved to: /content/drive/MyDrive/datasets/moco-frozen-1.pth\n",
            "Epoch execution time: 5 minutes!\n",
            "Remaining: 9 epochs, about 45 minutes!\n",
            "Best model is: 1\n",
            "Epoch 2, batch 10/372\n",
            "Epoch 2, batch 20/372\n",
            "Epoch 2, batch 30/372\n",
            "Epoch 2, batch 40/372\n",
            "Epoch 2, batch 50/372\n",
            "Epoch 2, batch 60/372\n",
            "Epoch 2, batch 70/372\n",
            "Epoch 2, batch 80/372\n",
            "Epoch 2, batch 90/372\n",
            "Epoch 2, batch 100/372\n",
            "Epoch 2, batch 110/372\n",
            "Epoch 2, batch 120/372\n",
            "Epoch 2, batch 130/372\n",
            "Epoch 2, batch 140/372\n",
            "Epoch 2, batch 150/372\n",
            "Epoch 2, batch 160/372\n",
            "Epoch 2, batch 170/372\n",
            "Epoch 2, batch 180/372\n",
            "Epoch 2, batch 190/372\n",
            "Epoch 2, batch 200/372\n",
            "Epoch 2, batch 210/372\n",
            "Epoch 2, batch 220/372\n",
            "Epoch 2, batch 230/372\n",
            "Epoch 2, batch 240/372\n",
            "Epoch 2, batch 250/372\n",
            "Epoch 2, batch 260/372\n",
            "Epoch 2, batch 270/372\n",
            "Epoch 2, batch 280/372\n",
            "Epoch 2, batch 290/372\n",
            "Epoch 2, batch 300/372\n",
            "Epoch 2, batch 310/372\n",
            "Epoch 2, batch 320/372\n",
            "Epoch 2, batch 330/372\n",
            "Epoch 2, batch 340/372\n",
            "Epoch 2, batch 350/372\n",
            "Epoch 2, batch 360/372\n",
            "Epoch 2, batch 370/372\n",
            "Epoch 2, batch 372/372\n",
            "Epoch 2, Training Loss: 1.467348559569287\n",
            "Validation Loss: 1.477532534372239\n",
            "Model saved to: /content/drive/MyDrive/datasets/moco-frozen-2.pth\n",
            "Epoch execution time: 5 minutes!\n",
            "Remaining: 8 epochs, about 40 minutes!\n",
            "Best model is: 2\n",
            "Epoch 3, batch 10/372\n",
            "Epoch 3, batch 20/372\n",
            "Epoch 3, batch 30/372\n",
            "Epoch 3, batch 40/372\n",
            "Epoch 3, batch 50/372\n",
            "Epoch 3, batch 60/372\n",
            "Epoch 3, batch 70/372\n",
            "Epoch 3, batch 80/372\n",
            "Epoch 3, batch 90/372\n",
            "Epoch 3, batch 100/372\n",
            "Epoch 3, batch 110/372\n",
            "Epoch 3, batch 120/372\n",
            "Epoch 3, batch 130/372\n",
            "Epoch 3, batch 140/372\n",
            "Epoch 3, batch 150/372\n",
            "Epoch 3, batch 160/372\n",
            "Epoch 3, batch 170/372\n",
            "Epoch 3, batch 180/372\n",
            "Epoch 3, batch 190/372\n",
            "Epoch 3, batch 200/372\n",
            "Epoch 3, batch 210/372\n",
            "Epoch 3, batch 220/372\n",
            "Epoch 3, batch 230/372\n",
            "Epoch 3, batch 240/372\n",
            "Epoch 3, batch 250/372\n",
            "Epoch 3, batch 260/372\n",
            "Epoch 3, batch 270/372\n",
            "Epoch 3, batch 280/372\n",
            "Epoch 3, batch 290/372\n",
            "Epoch 3, batch 300/372\n",
            "Epoch 3, batch 310/372\n",
            "Epoch 3, batch 320/372\n",
            "Epoch 3, batch 330/372\n",
            "Epoch 3, batch 340/372\n",
            "Epoch 3, batch 350/372\n",
            "Epoch 3, batch 360/372\n",
            "Epoch 3, batch 370/372\n",
            "Epoch 3, batch 372/372\n",
            "Epoch 3, Training Loss: 1.4382199872565526\n",
            "Validation Loss: 1.4730723055582198\n",
            "Model saved to: /content/drive/MyDrive/datasets/moco-frozen-3.pth\n",
            "Epoch execution time: 5 minutes!\n",
            "Remaining: 7 epochs, about 35 minutes!\n",
            "Best model is: 3\n",
            "Epoch 4, batch 10/372\n",
            "Epoch 4, batch 20/372\n",
            "Epoch 4, batch 30/372\n",
            "Epoch 4, batch 40/372\n",
            "Epoch 4, batch 50/372\n",
            "Epoch 4, batch 60/372\n",
            "Epoch 4, batch 70/372\n",
            "Epoch 4, batch 80/372\n",
            "Epoch 4, batch 90/372\n",
            "Epoch 4, batch 100/372\n",
            "Epoch 4, batch 110/372\n",
            "Epoch 4, batch 120/372\n",
            "Epoch 4, batch 130/372\n",
            "Epoch 4, batch 140/372\n",
            "Epoch 4, batch 150/372\n",
            "Epoch 4, batch 160/372\n",
            "Epoch 4, batch 170/372\n",
            "Epoch 4, batch 180/372\n",
            "Epoch 4, batch 190/372\n",
            "Epoch 4, batch 200/372\n",
            "Epoch 4, batch 210/372\n",
            "Epoch 4, batch 220/372\n",
            "Epoch 4, batch 230/372\n",
            "Epoch 4, batch 240/372\n",
            "Epoch 4, batch 250/372\n",
            "Epoch 4, batch 260/372\n",
            "Epoch 4, batch 270/372\n",
            "Epoch 4, batch 280/372\n",
            "Epoch 4, batch 290/372\n",
            "Epoch 4, batch 300/372\n",
            "Epoch 4, batch 310/372\n",
            "Epoch 4, batch 320/372\n",
            "Epoch 4, batch 330/372\n",
            "Epoch 4, batch 340/372\n",
            "Epoch 4, batch 350/372\n",
            "Epoch 4, batch 360/372\n",
            "Epoch 4, batch 370/372\n",
            "Epoch 4, batch 372/372\n",
            "Epoch 4, Training Loss: 1.4273814857006073\n",
            "Validation Loss: 1.467051873131404\n",
            "Model saved to: /content/drive/MyDrive/datasets/moco-frozen-4.pth\n",
            "Epoch execution time: 5 minutes!\n",
            "Remaining: 6 epochs, about 30 minutes!\n",
            "Best model is: 4\n",
            "Epoch 5, batch 10/372\n",
            "Epoch 5, batch 20/372\n",
            "Epoch 5, batch 30/372\n",
            "Epoch 5, batch 40/372\n",
            "Epoch 5, batch 50/372\n",
            "Epoch 5, batch 60/372\n",
            "Epoch 5, batch 70/372\n",
            "Epoch 5, batch 80/372\n",
            "Epoch 5, batch 90/372\n",
            "Epoch 5, batch 100/372\n",
            "Epoch 5, batch 110/372\n",
            "Epoch 5, batch 120/372\n",
            "Epoch 5, batch 130/372\n",
            "Epoch 5, batch 140/372\n",
            "Epoch 5, batch 150/372\n",
            "Epoch 5, batch 160/372\n",
            "Epoch 5, batch 170/372\n",
            "Epoch 5, batch 180/372\n",
            "Epoch 5, batch 190/372\n",
            "Epoch 5, batch 200/372\n",
            "Epoch 5, batch 210/372\n",
            "Epoch 5, batch 220/372\n",
            "Epoch 5, batch 230/372\n",
            "Epoch 5, batch 240/372\n",
            "Epoch 5, batch 250/372\n",
            "Epoch 5, batch 260/372\n",
            "Epoch 5, batch 270/372\n",
            "Epoch 5, batch 280/372\n",
            "Epoch 5, batch 290/372\n",
            "Epoch 5, batch 300/372\n",
            "Epoch 5, batch 310/372\n",
            "Epoch 5, batch 320/372\n",
            "Epoch 5, batch 330/372\n",
            "Epoch 5, batch 340/372\n",
            "Epoch 5, batch 350/372\n",
            "Epoch 5, batch 360/372\n",
            "Epoch 5, batch 370/372\n",
            "Epoch 5, batch 372/372\n",
            "Epoch 5, Training Loss: 1.4197377786841443\n",
            "Validation Loss: 1.4528227420080275\n",
            "Model saved to: /content/drive/MyDrive/datasets/moco-frozen-5.pth\n",
            "Epoch execution time: 5 minutes!\n",
            "Remaining: 5 epochs, about 25 minutes!\n",
            "Best model is: 5\n",
            "Epoch 6, batch 10/372\n",
            "Epoch 6, batch 20/372\n",
            "Epoch 6, batch 30/372\n",
            "Epoch 6, batch 40/372\n",
            "Epoch 6, batch 50/372\n",
            "Epoch 6, batch 60/372\n",
            "Epoch 6, batch 70/372\n",
            "Epoch 6, batch 80/372\n",
            "Epoch 6, batch 90/372\n",
            "Epoch 6, batch 100/372\n",
            "Epoch 6, batch 110/372\n",
            "Epoch 6, batch 120/372\n",
            "Epoch 6, batch 130/372\n",
            "Epoch 6, batch 140/372\n",
            "Epoch 6, batch 150/372\n",
            "Epoch 6, batch 160/372\n",
            "Epoch 6, batch 170/372\n",
            "Epoch 6, batch 180/372\n",
            "Epoch 6, batch 190/372\n",
            "Epoch 6, batch 200/372\n",
            "Epoch 6, batch 210/372\n",
            "Epoch 6, batch 220/372\n",
            "Epoch 6, batch 230/372\n",
            "Epoch 6, batch 240/372\n",
            "Epoch 6, batch 250/372\n",
            "Epoch 6, batch 260/372\n",
            "Epoch 6, batch 270/372\n",
            "Epoch 6, batch 280/372\n",
            "Epoch 6, batch 290/372\n",
            "Epoch 6, batch 300/372\n",
            "Epoch 6, batch 310/372\n",
            "Epoch 6, batch 320/372\n",
            "Epoch 6, batch 330/372\n",
            "Epoch 6, batch 340/372\n",
            "Epoch 6, batch 350/372\n",
            "Epoch 6, batch 360/372\n",
            "Epoch 6, batch 370/372\n",
            "Epoch 6, batch 372/372\n",
            "Epoch 6, Training Loss: 1.4090085731398674\n",
            "Validation Loss: 1.448922458149138\n",
            "Model saved to: /content/drive/MyDrive/datasets/moco-frozen-6.pth\n",
            "Epoch execution time: 5 minutes!\n",
            "Remaining: 4 epochs, about 20 minutes!\n",
            "Best model is: 6\n",
            "Epoch 7, batch 10/372\n",
            "Epoch 7, batch 20/372\n",
            "Epoch 7, batch 30/372\n",
            "Epoch 7, batch 40/372\n",
            "Epoch 7, batch 50/372\n",
            "Epoch 7, batch 60/372\n",
            "Epoch 7, batch 70/372\n",
            "Epoch 7, batch 80/372\n",
            "Epoch 7, batch 90/372\n",
            "Epoch 7, batch 100/372\n",
            "Epoch 7, batch 110/372\n",
            "Epoch 7, batch 120/372\n",
            "Epoch 7, batch 130/372\n",
            "Epoch 7, batch 140/372\n",
            "Epoch 7, batch 150/372\n",
            "Epoch 7, batch 160/372\n",
            "Epoch 7, batch 170/372\n",
            "Epoch 7, batch 180/372\n",
            "Epoch 7, batch 190/372\n",
            "Epoch 7, batch 200/372\n",
            "Epoch 7, batch 210/372\n",
            "Epoch 7, batch 220/372\n",
            "Epoch 7, batch 230/372\n",
            "Epoch 7, batch 240/372\n",
            "Epoch 7, batch 250/372\n",
            "Epoch 7, batch 260/372\n",
            "Epoch 7, batch 270/372\n",
            "Epoch 7, batch 280/372\n",
            "Epoch 7, batch 290/372\n",
            "Epoch 7, batch 300/372\n",
            "Epoch 7, batch 310/372\n",
            "Epoch 7, batch 320/372\n",
            "Epoch 7, batch 330/372\n",
            "Epoch 7, batch 340/372\n",
            "Epoch 7, batch 350/372\n",
            "Epoch 7, batch 360/372\n",
            "Epoch 7, batch 370/372\n",
            "Epoch 7, batch 372/372\n",
            "Epoch 7, Training Loss: 1.40444363317182\n",
            "Validation Loss: 1.4338413287722875\n",
            "Model saved to: /content/drive/MyDrive/datasets/moco-frozen-7.pth\n",
            "Epoch execution time: 5 minutes!\n",
            "Remaining: 3 epochs, about 15 minutes!\n",
            "Best model is: 7\n",
            "Epoch 8, batch 10/372\n",
            "Epoch 8, batch 20/372\n",
            "Epoch 8, batch 30/372\n",
            "Epoch 8, batch 40/372\n",
            "Epoch 8, batch 50/372\n",
            "Epoch 8, batch 60/372\n",
            "Epoch 8, batch 70/372\n",
            "Epoch 8, batch 80/372\n",
            "Epoch 8, batch 90/372\n",
            "Epoch 8, batch 100/372\n",
            "Epoch 8, batch 110/372\n",
            "Epoch 8, batch 120/372\n",
            "Epoch 8, batch 130/372\n",
            "Epoch 8, batch 140/372\n",
            "Epoch 8, batch 150/372\n",
            "Epoch 8, batch 160/372\n",
            "Epoch 8, batch 170/372\n",
            "Epoch 8, batch 180/372\n",
            "Epoch 8, batch 190/372\n",
            "Epoch 8, batch 200/372\n",
            "Epoch 8, batch 210/372\n",
            "Epoch 8, batch 220/372\n",
            "Epoch 8, batch 230/372\n",
            "Epoch 8, batch 240/372\n",
            "Epoch 8, batch 250/372\n",
            "Epoch 8, batch 260/372\n",
            "Epoch 8, batch 270/372\n",
            "Epoch 8, batch 280/372\n",
            "Epoch 8, batch 290/372\n",
            "Epoch 8, batch 300/372\n",
            "Epoch 8, batch 310/372\n",
            "Epoch 8, batch 320/372\n",
            "Epoch 8, batch 330/372\n",
            "Epoch 8, batch 340/372\n",
            "Epoch 8, batch 350/372\n",
            "Epoch 8, batch 360/372\n",
            "Epoch 8, batch 370/372\n",
            "Epoch 8, batch 372/372\n",
            "Epoch 8, Training Loss: 1.407778154457769\n",
            "Validation Loss: 1.447149365667313\n",
            "Model saved to: /content/drive/MyDrive/datasets/moco-frozen-8.pth\n",
            "Epoch execution time: 5 minutes!\n",
            "Remaining: 2 epochs, about 10 minutes!\n",
            "Best model is: 7\n",
            "Epoch 9, batch 10/372\n",
            "Epoch 9, batch 20/372\n",
            "Epoch 9, batch 30/372\n",
            "Epoch 9, batch 40/372\n",
            "Epoch 9, batch 50/372\n",
            "Epoch 9, batch 60/372\n",
            "Epoch 9, batch 70/372\n",
            "Epoch 9, batch 80/372\n",
            "Epoch 9, batch 90/372\n",
            "Epoch 9, batch 100/372\n",
            "Epoch 9, batch 110/372\n",
            "Epoch 9, batch 120/372\n",
            "Epoch 9, batch 130/372\n",
            "Epoch 9, batch 140/372\n",
            "Epoch 9, batch 150/372\n",
            "Epoch 9, batch 160/372\n",
            "Epoch 9, batch 170/372\n",
            "Epoch 9, batch 180/372\n",
            "Epoch 9, batch 190/372\n",
            "Epoch 9, batch 200/372\n",
            "Epoch 9, batch 210/372\n",
            "Epoch 9, batch 220/372\n",
            "Epoch 9, batch 230/372\n",
            "Epoch 9, batch 240/372\n",
            "Epoch 9, batch 250/372\n",
            "Epoch 9, batch 260/372\n",
            "Epoch 9, batch 270/372\n",
            "Epoch 9, batch 280/372\n",
            "Epoch 9, batch 290/372\n",
            "Epoch 9, batch 300/372\n",
            "Epoch 9, batch 310/372\n",
            "Epoch 9, batch 320/372\n",
            "Epoch 9, batch 330/372\n",
            "Epoch 9, batch 340/372\n",
            "Epoch 9, batch 350/372\n",
            "Epoch 9, batch 360/372\n",
            "Epoch 9, batch 370/372\n",
            "Epoch 9, batch 372/372\n",
            "Epoch 9, Training Loss: 1.399154011600761\n",
            "Validation Loss: 1.4281258696601504\n",
            "Model saved to: /content/drive/MyDrive/datasets/moco-frozen-9.pth\n",
            "Epoch execution time: 5 minutes!\n",
            "Remaining: 1 epochs, about 5 minutes!\n",
            "Best model is: 9\n",
            "Epoch 10, batch 10/372\n",
            "Epoch 10, batch 20/372\n",
            "Epoch 10, batch 30/372\n",
            "Epoch 10, batch 40/372\n",
            "Epoch 10, batch 50/372\n",
            "Epoch 10, batch 60/372\n",
            "Epoch 10, batch 70/372\n",
            "Epoch 10, batch 80/372\n",
            "Epoch 10, batch 90/372\n",
            "Epoch 10, batch 100/372\n",
            "Epoch 10, batch 110/372\n",
            "Epoch 10, batch 120/372\n",
            "Epoch 10, batch 130/372\n",
            "Epoch 10, batch 140/372\n",
            "Epoch 10, batch 150/372\n",
            "Epoch 10, batch 160/372\n",
            "Epoch 10, batch 170/372\n",
            "Epoch 10, batch 180/372\n",
            "Epoch 10, batch 190/372\n",
            "Epoch 10, batch 200/372\n",
            "Epoch 10, batch 210/372\n",
            "Epoch 10, batch 220/372\n",
            "Epoch 10, batch 230/372\n",
            "Epoch 10, batch 240/372\n",
            "Epoch 10, batch 250/372\n",
            "Epoch 10, batch 260/372\n",
            "Epoch 10, batch 270/372\n",
            "Epoch 10, batch 280/372\n",
            "Epoch 10, batch 290/372\n",
            "Epoch 10, batch 300/372\n",
            "Epoch 10, batch 310/372\n",
            "Epoch 10, batch 320/372\n",
            "Epoch 10, batch 330/372\n",
            "Epoch 10, batch 340/372\n",
            "Epoch 10, batch 350/372\n",
            "Epoch 10, batch 360/372\n",
            "Epoch 10, batch 370/372\n",
            "Epoch 10, batch 372/372\n",
            "Epoch 10, Training Loss: 1.4014353845068204\n",
            "Validation Loss: 1.4250058749365428\n",
            "Model saved to: /content/drive/MyDrive/datasets/moco-frozen-10.pth\n",
            "Epoch execution time: 5 minutes!\n",
            "Remaining: 0 epochs, about 0 minutes!\n",
            "Best model is: 10\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimSiamModel\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Choose optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Training loop\n",
        "num_epochs=10\n",
        "print_every=10\n",
        "best_model = 0\n",
        "best_val_loss_avg=float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    total_batches = len(loader)\n",
        "    for batch_idx, (images, labels) in enumerate(loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        if (batch_idx + 1) % print_every == 0 or (batch_idx + 1) == total_batches:\n",
        "          print(f\"Epoch {epoch+1}, batch {batch_idx+1}/{total_batches}\")\n",
        "        optimizer.zero_grad()\n",
        "        labels = labels.squeeze(1)\n",
        "        # print(f\"images shape: {images.shape}\")\n",
        "        outputs = model(images)\n",
        "        # print(f\"outputs shape: {outputs.shape}\")\n",
        "        labels = labels.long()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Training Loss: {running_loss / len(loader)}\")\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    val_running_loss = 0.0\n",
        "    val_total_batches = len(loader_val)\n",
        "\n",
        "    with torch.no_grad():  # Turn off gradient calculation during validation\n",
        "        for batch_idx, (val_images, val_labels) in enumerate(loader_val):\n",
        "            val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
        "            val_labels = val_labels.squeeze(1)\n",
        "            val_outputs = model(val_images)\n",
        "            val_labels = val_labels.long()\n",
        "            val_loss = criterion(val_outputs, val_labels)\n",
        "            val_running_loss += val_loss.item()\n",
        "\n",
        "    val_loss_avg = val_running_loss / len(loader_val)\n",
        "    print(f\"Validation Loss: {val_loss_avg}\")\n",
        "    model_save_path = f\"/content/drive/MyDrive/datasets/simsiam-frozen-{epoch+1}.pth\"\n",
        "    torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': criterion,\n",
        "                }, model_save_path)\n",
        "    print(f\"Model saved to: {model_save_path}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    execution_time = int(execution_time/60)\n",
        "    print(\"Epoch execution time:\", execution_time, \"minutes!\")\n",
        "    print(f\"Remaining: {(num_epochs-epoch-1)} epochs, about {(num_epochs-epoch-1)*execution_time} minutes!\")\n",
        "\n",
        "    if (val_loss_avg<best_val_loss_avg):\n",
        "      best_val_loss_avg=val_loss_avg\n",
        "      best_model=epoch+1\n",
        "    print(f\"Best model is: {best_model}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}